# MultiCloudDevOps
 
## :computer: MultiCloud com DevOps utilizando com provisionamento Terraform

## ðŸ›  Provisionar Banco de Dados MYSQL na Google Cloud , Clusters do GKE - kubernetes e Bucket no S3 AWS 

âš¡ MissÃ£o 1

âš¡ Amazon Web Services (AWS)

1. Acessar a console da AWS. Na barra de pesquisas, digite IAM. Na seÃ§Ã£o Services, clique em IAM.  ðŸ‘‹

2. Clique em Add user, insira o nome terraform-pt-1 e clique em Next para criar o usuÃ¡rio do tipo programmatic.  ðŸ‘‹

![image](https://user-images.githubusercontent.com/76752875/231753016-75ffea2d-a9ed-4c19-b264-12038c89919d.png)

3. ApÃ³s avanÃ§ar, em Set permissions, clique no botÃ£o Attach existing policies directly. ðŸ‘‹

![image](https://user-images.githubusercontent.com/76752875/231754740-d41b160a-dddb-4797-8c90-d23c0f0c49f2.png)

4. Digite AmazonS3FullAccess em Filter distributions by text, property or value e aperte Enter. ðŸ‘‹

5. Selecione AmazonS3FullAccess. ðŸ‘‹

![image](https://user-images.githubusercontent.com/76752875/231755714-d06d4e66-dd65-4b2d-bee5-d8a44fbf8169.png)

6. Clique em Next. ðŸ‘‹

7. Revise todos os detalhes. ðŸ‘‹

8. Clique em Create user.ðŸ‘‹

âš¡ [NEW] AWS has recently changed the way to create/download the access key. Follow the new steps:

9. Acesse o usuÃ¡rio terraform-pt-1.ðŸ‘‹

11. Clique em Security credentials.ðŸ‘‹

12. Navegue atÃ© a seÃ§Ã£o Access keys.ðŸ‘‹

13. Clique em Create access key.ðŸ‘‹

![image](https://user-images.githubusercontent.com/76752875/231761785-8d8ac147-8bf4-4626-9427-33eb56fa4288.png)

14. Selecione Command Line Interface (CLI) e I understand the above recommendation and want to proceed to create an access key.ðŸ‘‹

15. Clique em Next.ðŸ‘‹

16. Clique em Create access key.ðŸ‘‹

17. Clique em Download .csv file.ðŸ‘‹

18. ApÃ³s o download finalizar, clique em Done.ðŸ‘‹

19. Com o download feito, renomeie o .csv para accessKeys.csv.ðŸ‘‹

## ðŸ›  Google Cloud Platform (GCP)

20. Baixar projeto do git "mission1.zip".ðŸ‘‹

21. Acessar a console da GCP e abrir o Cloud ShellðŸ‘‹

22. Fazer o upload dos arquivos accessKeys.csv e mission1.zip para o Cloud ShellðŸ‘‹

23. ApÃ³s fazer o upload, executar os comandos de preparaÃ§Ã£o dos arquivos:ðŸ‘‹

```bash
       mkdir mission1_pt
       mv mission1.zip mission1_pt
       cd mission1_pt
       unzip mission1.zip
       mv ~/accessKeys.csv mission1/pt
       cd mission1/pt
       chmod +x *.sh
```

24. ApÃ³s fazer o upload, executar os comandos de preparaÃ§Ã£o dos arquivos:ðŸ‘‹

```bash
       ./aws_set_credentials.sh accessKeys.csv
       gcloud config set project <your-project-id>
```

25. Clique em Autorize e execute o comando abaixo para setar o projeto no Google Cloud Shell

```bash
      ./gcp_set_project.sh
```
26. Execute o comando para habilitar as APIs do Kubernetes, Container Registry e Cloud SQL

```bash
      gcloud services enable containerregistry.googleapis.com
      gcloud services enable container.googleapis.com
      gcloud services enable sqladmin.googleapis.com
```

## ðŸ›  OBS IMPORTANTE (NÃƒO PULE ESTE PASSO):

## ðŸ› Antes de executar os comandos do terraform, abra o Google Cloud Editor e atualizar o arquivo tcb_aws_storage.tf substituindo o nome do bucket para um exclusivo    (na AWS, os buckets precisam ter nomes Ãºnicos).






```bash
Tornar o Bucket Privado - inserir o codigo no arquivo e executar os comandos "terraform plan" e "terraform apply"

  resource "aws_s3_bucket_public_access_block" "s3_block" {
  bucket = aws_s3_bucket.s3_bucket.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```


<p align="center">
âš¡ DocumentaÃ§Ã£o ðŸ‘‹
    (https://registry.terraform.io/providers/hashicorp/aws/latest/docs)
</p>   

